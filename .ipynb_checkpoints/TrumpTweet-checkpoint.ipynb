{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrumpTweet Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare environment\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data file with the Tweets\n",
    "df_tt = pd.read_csv('inputdata/tweets_11-06-2020.csv')\n",
    "df_tt['date'] = pd.to_datetime(df_tt['date'])\n",
    "\n",
    "#Get the number of tweets sent by Trump himself\n",
    "#print('The number of tweets and retweets: ')\n",
    "#print(df_tt.groupby('isRetweet').size())\n",
    "df_tt = df_tt[df_tt['isRetweet']=='f']\n",
    "df_tt = df_tt[df_tt['date'].between('2016-01-01','2020-11-19')]\n",
    "\n",
    "# Output just the Tweets to a text file\n",
    "df_tt['text'].to_csv('inputdata/tweets.txt',  header=None, index=None, sep=' ', mode='a')\n",
    "\n",
    "# load ascii text and remove url's from the tweets\n",
    "filename = \"inputdata/tweets.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = re.sub(r'http\\S+', '', raw_text)\n",
    "\n",
    "# Create a file with the url's removed\n",
    "with open('inputdata/clean_tweet.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23600967"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters 779\n",
      "The dataset size is 1\n",
      "Total number of data windows: 26507755\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text\n",
    "tok = keras.preprocessing.text.Tokenizer(char_level=True,num_words=100,oov_token='<unk>')\n",
    "fit_text = tok.fit_on_texts([raw_text])\n",
    "\n",
    "max_id = len(tok.word_index)\n",
    "ds_size = tok.document_count\n",
    "\n",
    "print('Number of distinct characters {}'.format(max_id))\n",
    "print('The dataset size is {}'.format(ds_size))\n",
    "\n",
    "#reduce max characters to 100\n",
    "#max_id = 100\n",
    "\n",
    "# Encode the full text so each char is represented by its ID\n",
    "[encoded] = np.array(tok.texts_to_sequences([raw_text])) - 1 # -1 so we have 0-38\n",
    "\n",
    "#split the dataset for training and test if needed\n",
    "train_size = int(ds_size*.9)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded)\n",
    "\n",
    "# Create the character sequences\n",
    "n_steps = 140 # each character sequence is 100 steps\n",
    "window_length = n_steps + 1 #target is the input steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
    "print('Total number of data windows: {}'.format(len(dataset)))\n",
    "\n",
    "# flatten to 2d\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(1000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:,:-1],windows[:,1:]))\n",
    "\n",
    "# one-hot encode unique characters (48 of them)\n",
    "dataset = dataset.map(lambda x_batch, y_batch: (tf.one_hot(x_batch, depth=max_id), y_batch))\n",
    "\n",
    "# pre-fetch\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6898013"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Character Generation Model\n",
    "Stateless RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "432/432 [==============================] - 343s 793ms/step - loss: 3.3018\n",
      "Epoch 2/20\n",
      "432/432 [==============================] - 343s 794ms/step - loss: 3.1701\n",
      "Epoch 3/20\n",
      "432/432 [==============================] - 344s 796ms/step - loss: 3.1694\n",
      "Epoch 4/20\n",
      "432/432 [==============================] - 348s 806ms/step - loss: 3.1689\n",
      "Epoch 5/20\n",
      "432/432 [==============================] - 354s 819ms/step - loss: 3.1692\n",
      "Epoch 6/20\n",
      "432/432 [==============================] - 357s 827ms/step - loss: 3.1689\n",
      "Epoch 7/20\n",
      "432/432 [==============================] - 352s 815ms/step - loss: 3.1689\n",
      "Epoch 8/20\n",
      "432/432 [==============================] - 349s 808ms/step - loss: 2.8409\n",
      "Epoch 9/20\n",
      "432/432 [==============================] - 349s 807ms/step - loss: 2.2847\n",
      "Epoch 10/20\n",
      "432/432 [==============================] - 346s 802ms/step - loss: 2.1076\n",
      "Epoch 11/20\n",
      "432/432 [==============================] - 354s 820ms/step - loss: 2.0184\n",
      "Epoch 12/20\n",
      "432/432 [==============================] - 354s 818ms/step - loss: 1.9613\n",
      "Epoch 13/20\n",
      "432/432 [==============================] - 349s 809ms/step - loss: 1.9206\n",
      "Epoch 14/20\n",
      "432/432 [==============================] - 348s 805ms/step - loss: 1.8878\n",
      "Epoch 15/20\n",
      "432/432 [==============================] - 349s 807ms/step - loss: 1.8607\n",
      "Epoch 16/20\n",
      "432/432 [==============================] - 348s 806ms/step - loss: 1.8392\n",
      "Epoch 17/20\n",
      "432/432 [==============================] - 350s 811ms/step - loss: 1.8206\n",
      "Epoch 18/20\n",
      "432/432 [==============================] - 350s 810ms/step - loss: 1.8047\n",
      "Epoch 19/20\n",
      "432/432 [==============================] - 349s 807ms/step - loss: 1.7910\n",
      "Epoch 20/20\n",
      "432/432 [==============================] - 350s 810ms/step - loss: 1.7804\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "\n",
    "# define the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(512, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')\n",
    "\n",
    "# Save a checkpoint after every epoch\n",
    "EPOCHS = 20\n",
    "checkpoint_filepath = 'checkpoints/weights.{epoch:02d}.hdf5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False)\n",
    "\n",
    "#Fit the model\n",
    "history = model.fit(dataset,epochs=EPOCHS,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate some tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grab them by the pussy to the democrats and state that the democrats and a great the fake a great the fake a great and the work be a great the was the work a grea\n"
     ]
    }
   ],
   "source": [
    "# Create function to process text for prediction (seed text)\n",
    "def preprocess(texts):\n",
    "    x = np.array(tok.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(x, max_id)\n",
    "\n",
    "# Create a function to create next character using temperature\n",
    "def next_char(text, temperature=1):\n",
    "    x_new = preprocess([text])\n",
    "    y_proba = model.predict(x_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba)/temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tok.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "# Function to recursively generate text\n",
    "def complete_text(text, n_chars=140, temperature=.2):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text\n",
    "\n",
    "# Create a single letter prediction\n",
    "seed_text='t'\n",
    "x_seed = preprocess([seed_text])\n",
    "y_pred = model.predict_classes(x_seed)\n",
    "tok.sequences_to_texts(y_pred + 1)[0][-1]\n",
    "\n",
    "# Create a long sequence of text\n",
    "print(complete_text('grab them by the pussy', temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
