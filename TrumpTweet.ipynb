{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrumpTweet Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare environment\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data file with the Tweets\n",
    "df_tt = pd.read_csv('inputdata/tweets_11-06-2020.csv')\n",
    "df_tt['date'] = pd.to_datetime(df_tt['date'])\n",
    "\n",
    "#Get the number of tweets sent by Trump himself\n",
    "#print('The number of tweets and retweets: ')\n",
    "#print(df_tt.groupby('isRetweet').size())\n",
    "df_tt = df_tt[df_tt['isRetweet']=='f']\n",
    "df_tt = df_tt[df_tt['date'].between('2020-01-01','2020-11-19')]\n",
    "\n",
    "# Output just the Tweets to a text file\n",
    "df_tt['text'].to_csv('inputdata/tweets.txt',  header=None, index=None, sep=' ', mode='a')\n",
    "\n",
    "# load ascii text and remove url's from the tweets\n",
    "filename = \"inputdata/tweets.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = re.sub(r'http\\S+', '', raw_text)\n",
    "\n",
    "# Create a file with the url's removed\n",
    "with open('inputdata/clean_tweet.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724933"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters 194\n",
      "The dataset size is 1\n",
      "Total number of data windows: 724793\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text\n",
    "tok = keras.preprocessing.text.Tokenizer(char_level=True, filters='!\"#$%&()*+,-./:;<=>?[\\\\]^_`{|}~\\t\\n')\n",
    "fit_text = tok.fit_on_texts([raw_text])\n",
    "\n",
    "max_id = len(tok.word_index)\n",
    "ds_size = tok.document_count\n",
    "\n",
    "print('Number of distinct characters {}'.format(max_id))\n",
    "print('The dataset size is {}'.format(ds_size))\n",
    "\n",
    "#reduce max characters to 100\n",
    "#max_id = 100\n",
    "\n",
    "# Encode the full text so each char is represented by its ID\n",
    "[encoded] = np.array(tok.texts_to_sequences([raw_text])) - 1 # -1 so we have 0-38\n",
    "\n",
    "#split the dataset for training and test if needed\n",
    "train_size = int(ds_size*.9)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded)\n",
    "\n",
    "# Create the character sequences\n",
    "n_steps = 140 # each character sequence is 100 steps\n",
    "window_length = n_steps + 1 #target is the input steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
    "print('Total number of data windows: {}'.format(len(dataset)))\n",
    "\n",
    "# flatten to 2d\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(1000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:,:-1],windows[:,1:]))\n",
    "\n",
    "# one-hot encode unique characters (48 of them)\n",
    "dataset = dataset.map(lambda x_batch, y_batch: (tf.one_hot(x_batch, depth=max_id), y_batch))\n",
    "\n",
    "# pre-fetch\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6898013"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Character Generation Model\n",
    "Stateless RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22650/22650 [==============================] - 75845s 3s/step - loss: 1.2303\n",
      "Epoch 2/20\n",
      "  481/22650 [..............................] - ETA: 21:36:49 - loss: 1.0885"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "\n",
    "# define the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(512, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')\n",
    "\n",
    "# Save a checkpoint after every epoch\n",
    "EPOCHS = 20\n",
    "checkpoint_filepath = 'checkpoints/weights.{epoch:02d}.hdf5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False)\n",
    "\n",
    "#Fit the model\n",
    "history = model.fit(dataset,epochs=EPOCHS,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate some tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grab them by the pussy to the democrats and state that the democrats and a great the fake a great the fake a great and the work be a great the was the work a grea\n"
     ]
    }
   ],
   "source": [
    "# Create function to process text for prediction (seed text)\n",
    "def preprocess(texts):\n",
    "    x = np.array(tok.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(x, max_id)\n",
    "\n",
    "# Create a function to create next character using temperature\n",
    "def next_char(text, temperature=1):\n",
    "    x_new = preprocess([text])\n",
    "    y_proba = model.predict(x_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba)/temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tok.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "# Function to recursively generate text\n",
    "def complete_text(text, n_chars=140, temperature=.2):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text\n",
    "\n",
    "# Create a single letter prediction\n",
    "seed_text='t'\n",
    "x_seed = preprocess([seed_text])\n",
    "y_pred = model.predict_classes(x_seed)\n",
    "tok.sequences_to_texts(y_pred + 1)[0][-1]\n",
    "\n",
    "# Create a long sequence of text\n",
    "print(complete_text('grab them by the pussy', temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
